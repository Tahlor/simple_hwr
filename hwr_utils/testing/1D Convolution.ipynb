{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np  \n",
    "from torch import nn, tensor, Tensor\n",
    "from torch.nn import functional as F \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_x = np.random.randint(0,10,20)\n",
    "rel_x = np.array(range(0,20))\n",
    "rel_y = np.random.randint(0,10,20)\n",
    "rel_y = np.array(range(0,20))\n",
    "start = np.random.randint(0,2,20)\n",
    "\n",
    "gt = np.c_[rel_x, rel_y, start][np.newaxis] # add batch and channel\n",
    "gt = gt.transpose(0,2,1) # BATCH, CHANNELS (3), LENGTH\n",
    "kernel = np.cumsum([.1]*10)\n",
    "inverse_kenel\n",
    "#gt = rel_x[np.newaxis, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "  [ 0  4  5  4  4  0  4  1  9  6  1  5  6  7  5  5  4  1  7  8]\n",
      "  [ 1  1  0  0  1  1  1  1  0  1  1  1  1  1  0  0  0  0  1  1]]]\n",
      "(1, 3, 20)\n",
      "[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "print(gt)\n",
    "print(gt.shape)\n",
    "print(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "          0.9000, 1.0000],\n",
      "         [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "          0.9000, 1.0000],\n",
      "         [0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "          0.9000, 1.0000]]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected stride to be a single integer value or a list of 1 values to match the convolution dimensions, but got stride=[1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-d7a1db59ed66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hwr5/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hwr5/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hwr5/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected stride to be a single integer value or a list of 1 values to match the convolution dimensions, but got stride=[1, 1]"
     ]
    }
   ],
   "source": [
    "#m = nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "channels = 3\n",
    "conv = nn.Conv1d(channels, channels, 10, stride=1, padding=9, dilation=1, groups=1, bias=False, padding_mode='zeros')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight = nn.Parameter(Tensor(kernel).repeat(1, channels, 1))\n",
    "    print(conv.weight)\n",
    "out = conv(Tensor(gt))\n",
    "print(out.size())\n",
    "print(out[:,:,:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "           0.9000, 1.0000]]]], requires_grad=True)\n",
      "torch.Size([1, 1, 3, 29])\n",
      "tensor([[[[ 0.0000,  1.0000,  2.9000,  5.6000,  9.0000, 13.0000, 17.5000,\n",
      "           22.4000, 27.6000, 33.0000, 38.5000, 44.0000, 49.5000, 55.0000,\n",
      "           60.5000, 66.0000, 71.5000, 77.0000, 82.5000, 88.0000],\n",
      "          [ 0.0000,  4.0000,  8.6000, 11.7000, 14.4000, 12.7000, 15.0000,\n",
      "           13.9000, 20.7000, 23.6000, 20.9000, 22.1000, 24.2000, 27.2000,\n",
      "           27.9000, 28.5000, 27.6000, 23.7000, 25.8000, 29.1000],\n",
      "          [ 1.0000,  1.9000,  1.7000,  1.5000,  2.3000,  3.0000,  3.6000,\n",
      "            4.1000,  3.5000,  3.9000,  4.2000,  4.5000,  4.8000,  5.0000,\n",
      "            4.1000,  3.3000,  2.6000,  2.0000,  2.5000,  2.9000]]]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#m = nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "channels = 1\n",
    "conv = nn.Conv2d(1, 1, 10, stride=1, padding=[0,9], dilation=1, groups=1, bias=False, padding_mode='zeros')\n",
    "\n",
    "conv.weight = nn.Parameter(Tensor(kernel).repeat(1, channels, 1, 1))\n",
    "print(conv.weight)\n",
    "\n",
    "out = conv(Tensor(gt[np.newaxis]))\n",
    "print(out.size())\n",
    "print(out[:,:,:,:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10]) (20, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight 1 1 10, but got 2-dimensional input of size [20, 3] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-16db1cb6b748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight 1 1 10, but got 2-dimensional input of size [20, 3] instead"
     ]
    }
   ],
   "source": [
    "## Functional approach\n",
    "weights = tensor(kernel).repeat(1, 1, 1)\n",
    "print(weights.shape, gt.shape)\n",
    "\n",
    "output = F.conv1d(tensor(gt), weights)\n",
    "# torch.nn.functional.conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-90ccdab17b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "weights = tensor([[0.0, 0, 0], [0, 1, 0], [0, 0, 0]]).unsqueeze(0).unsqueeze(0)\n",
    "weights.requires_grad = True\n",
    "\n",
    "conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight = nn.Parameter(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([[0., 0., 0.],\n",
    "                        [0., 1., 0.],\n",
    "                        [0., 0., 0.]])\n",
    "weights = weights.view(1, 1, 3, 3) \n",
    "print(weights)\n",
    "weights = weights.repeat(1, nb_channels, 1, 1)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tensor([[0.0, 0, 0], [0, 1, 0], [0, 0, 0]]).unsqueeze(0).unsqueeze(0)\n",
    "weights.requires_grad = True\n",
    "\n",
    "conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight = nn.Parameter(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have input of dimension 32 x 100 x 1 where 32 is the batch size.\n",
    "# I wanted to convolved over 100 x 1 array in the input for each of the 32 such arrays i.e. a single data point in the batch has an array like that.\n",
    "# I hoped that conv1d(100, 100, 1) layer will work.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "a = torch.randn(32, 100, 1)  \n",
    "m = nn.Conv1d(100, 100, 1) \n",
    "out = m(a)\n",
    "print(out.size())\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([0,.4,1,1.4,2,2.9,3.6,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.round(x[1:])!=np.round(x[:-1]))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function conv_window at 0x7f3ada696a60>\n",
      "tensor([[[ 0.,  4.,  0.],\n",
      "         [ 1.,  8.,  1.],\n",
      "         [ 2.,  9.,  1.],\n",
      "         [ 3.,  2.,  0.],\n",
      "         [ 4.,  7.,  1.],\n",
      "         [ 5.,  1.,  1.],\n",
      "         [ 6.,  9.,  1.],\n",
      "         [ 7.,  3.,  1.],\n",
      "         [ 8.,  6.,  1.],\n",
      "         [ 9.,  7.,  0.],\n",
      "         [10.,  3.,  0.],\n",
      "         [11.,  9.,  0.],\n",
      "         [12.,  3.,  0.],\n",
      "         [13.,  0.,  0.],\n",
      "         [14.,  1.,  1.],\n",
      "         [15.,  7.,  1.],\n",
      "         [16.,  0.,  0.],\n",
      "         [17.,  3.,  1.],\n",
      "         [18.,  9.,  0.],\n",
      "         [19.,  5.,  0.]]])\n",
      "tensor([[[  0.,   4.,   0.],\n",
      "         [  1.,  12.,   1.],\n",
      "         [  3.,  21.,   2.],\n",
      "         [  6.,  23.,   2.],\n",
      "         [ 10.,  30.,   3.],\n",
      "         [ 15.,  31.,   4.],\n",
      "         [ 21.,  40.,   5.],\n",
      "         [ 28.,  43.,   6.],\n",
      "         [ 36.,  49.,   7.],\n",
      "         [ 45.,  56.,   7.],\n",
      "         [ 55.,  59.,   7.],\n",
      "         [ 66.,  68.,   7.],\n",
      "         [ 78.,  71.,   7.],\n",
      "         [ 91.,  71.,   7.],\n",
      "         [105.,  72.,   8.],\n",
      "         [120.,  79.,   9.],\n",
      "         [136.,  79.,   9.],\n",
      "         [153.,  82.,  10.],\n",
      "         [171.,  91.,  10.],\n",
      "         [190.,  96.,  10.]]])\n",
      "tensor([[[  0.,   4.,   0.],\n",
      "         [  1.,   8.,   1.],\n",
      "         [  3.,   9.,   2.],\n",
      "         [  6.,   2.,   2.],\n",
      "         [ 10.,   7.,   3.],\n",
      "         [ 15.,   1.,   4.],\n",
      "         [ 21.,   9.,   5.],\n",
      "         [ 28.,   3.,   6.],\n",
      "         [ 36.,   6.,   7.],\n",
      "         [ 45.,   7.,   7.],\n",
      "         [ 55.,   3.,   7.],\n",
      "         [ 66.,   9.,   7.],\n",
      "         [ 78.,   3.,   7.],\n",
      "         [ 91.,   0.,   7.],\n",
      "         [105.,   1.,   8.],\n",
      "         [120.,   7.,   9.],\n",
      "         [136.,   0.,   9.],\n",
      "         [153.,   3.,  10.],\n",
      "         [171.,   9.,  10.],\n",
      "         [190.,   5.,  10.]],\n",
      "\n",
      "        [[  0.,   4.,   0.],\n",
      "         [  1.,   8.,   1.],\n",
      "         [  3.,   9.,   2.],\n",
      "         [  6.,   2.,   2.],\n",
      "         [ 10.,   7.,   3.],\n",
      "         [ 15.,   1.,   4.],\n",
      "         [ 21.,   9.,   5.],\n",
      "         [ 28.,   3.,   6.],\n",
      "         [ 36.,   6.,   7.],\n",
      "         [ 45.,   7.,   7.],\n",
      "         [ 55.,   3.,   7.],\n",
      "         [ 66.,   9.,   7.],\n",
      "         [ 78.,   3.,   7.],\n",
      "         [ 91.,   0.,   7.],\n",
      "         [105.,   1.,   8.],\n",
      "         [120.,   7.,   9.],\n",
      "         [136.,   0.,   9.],\n",
      "         [153.,   3.,  10.],\n",
      "         [171.,   9.,  10.],\n",
      "         [190.,   5.,  10.]]])\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from stroke_recovery import conv_window\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "gt_length = 20\n",
    "rel_x = np.array(range(0,gt_length))\n",
    "rel_y = np.random.randint(0, 10, 20)\n",
    "start = np.random.randint(0, 2, gt_length)\n",
    "\n",
    "gt = np.c_[rel_x, rel_y, start][np.newaxis]  # BATCH, WIDTH, HEIGHT/VOCAB\n",
    "pred = gt.copy()\n",
    "pred[:, 7, 0] = 12\n",
    "\n",
    "pred = Tensor(pred)  # relative\n",
    "gt = Tensor(gt)\n",
    "gt_rel = Tensor(gt)\n",
    "gt = torch.cumsum(gt, dim=1)  # abs\n",
    "\n",
    "for conv_func in [conv_window]:\n",
    "    print(conv_func)\n",
    "    # Anything with itself should be equivalent to a cumulative sum\n",
    "    x = conv_func(gt,gt_rel.clone())\n",
    "    np.testing.assert_almost_equal(x.numpy(), gt, decimal=5)\n",
    "\n",
    "    # Should get back on track\n",
    "    x = conv_func(gt,pred.clone())\n",
    "    np.testing.assert_almost_equal(x[:,-4:].numpy(), gt[:,-4:], decimal=5)\n",
    "    np.testing.assert_almost_equal(x[:,0:6].numpy(), gt[:,0:6], decimal=5)\n",
    "\n",
    "    # With batching\n",
    "    gt2 = Tensor(np.r_[gt,gt])\n",
    "    gt2_rel = Tensor(np.r_[gt_rel.clone(),gt_rel.clone()]) # pred is relative\n",
    "    x = conv_func(gt2,gt2_rel)\n",
    "    np.testing.assert_almost_equal(x.numpy(), gt2, decimal=5)\n",
    "\n",
    "    # With batching + index\n",
    "    gt2 = Tensor(np.r_[gt,gt])\n",
    "    gt2_rel = Tensor(np.r_[gt_rel.clone(),gt_rel.clone()]) # pred is relative\n",
    "    x = conv_func(gt2,gt2_rel, indices=[0,2])\n",
    "    np.testing.assert_almost_equal(x.numpy()[:,:,1], gt2_rel[:,:,1], decimal=5)\n",
    "    np.testing.assert_almost_equal(x.numpy()[:,:,0], gt2[:,:,0], decimal=5)\n",
    "\n",
    "print(gt_rel)\n",
    "print(gt)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwr5",
   "language": "python",
   "name": "hwr5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
