{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np  \n",
    "from torch import nn, tensor, Tensor\n",
    "from torch.nn import functional\n",
    "import sys, os\n",
    "sys.path.append(\"../..\")\n",
    "from hwr_utils.stroke_recovery import relativefy_batch_torch, test_conv_weight, conv_weight\n",
    "\n",
    "test_conv_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_length = 20\n",
    "rel_x = np.random.randint(0,10,20)\n",
    "#rel_x = np.array(range(0,gt_length))\n",
    "rel_y = np.random.randint(0,10,20)\n",
    "#rel_y = np.array(range(0,gt_length))\n",
    "start = np.random.randint(0,2,gt_length)\n",
    "\n",
    "gt = np.c_[rel_x, rel_y, start][np.newaxis] # BATCH, WIDTH, HEIGHT/VOCAB\n",
    "pred = gt.copy()\n",
    "pred[:,7,0] = 12\n",
    "\n",
    "# Batch it up\n",
    "# gt = np.r_[gt, pred]\n",
    "# print(gt.shape)\n",
    "\n",
    "pred = Tensor(pred) # relative\n",
    "gt = Tensor(gt)\n",
    "gt_rel = Tensor(gt)\n",
    "gt = torch.cumsum(gt, dim=1) # abs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  9.,   9.,   1.],\n",
      "         [ 10.,  16.,   2.],\n",
      "         [ 12.,  17.,   2.],\n",
      "         [ 12.,  19.,   3.],\n",
      "         [ 16.,  26.,   4.],\n",
      "         [ 16.,  30.,   4.],\n",
      "         [ 22.,  36.,   4.],\n",
      "         [ 26.,  45.,   4.],\n",
      "         [ 32.,  52.,   5.],\n",
      "         [ 34.,  54.,   5.],\n",
      "         [ 42.,  63.,   5.],\n",
      "         [ 50.,  67.,   5.],\n",
      "         [ 50.,  75.,   5.],\n",
      "         [ 54.,  80.,   6.],\n",
      "         [ 59.,  87.,   7.],\n",
      "         [ 62.,  96.,   8.],\n",
      "         [ 68., 103.,   9.],\n",
      "         [ 73., 107.,  10.],\n",
      "         [ 73., 114.,  10.],\n",
      "         [ 76., 122.,  10.]],\n",
      "\n",
      "        [[  9.,   9.,   1.],\n",
      "         [ 10.,  16.,   2.],\n",
      "         [ 12.,  17.,   2.],\n",
      "         [ 12.,  19.,   3.],\n",
      "         [ 16.,  26.,   4.],\n",
      "         [ 16.,  30.,   4.],\n",
      "         [ 22.,  36.,   4.],\n",
      "         [ 26.,  45.,   4.],\n",
      "         [ 32.,  52.,   5.],\n",
      "         [ 34.,  54.,   5.],\n",
      "         [ 42.,  63.,   5.],\n",
      "         [ 50.,  67.,   5.],\n",
      "         [ 50.,  75.,   5.],\n",
      "         [ 54.,  80.,   6.],\n",
      "         [ 59.,  87.,   7.],\n",
      "         [ 62.,  96.,   8.],\n",
      "         [ 68., 103.,   9.],\n",
      "         [ 73., 107.,  10.],\n",
      "         [ 73., 114.,  10.],\n",
      "         [ 76., 122.,  10.]]]) tensor([[[  9.0000,   9.0000,   1.0000],\n",
      "         [  1.0000,  16.0000,   1.0000],\n",
      "         [  2.0000,  17.0000,   0.0000],\n",
      "         [  0.0000,  19.0000,   1.0000],\n",
      "         [  4.0000,  26.0000,   1.0000],\n",
      "         [  0.0000,  30.0000,   0.0000],\n",
      "         [  6.0000,  36.0000,   0.0000],\n",
      "         [  4.0000,  45.0000,   0.0000],\n",
      "         [  6.0000,  52.0000,   1.0000],\n",
      "         [  2.0000,  54.0000,   0.0000],\n",
      "         [  8.0000,  63.0000,   0.0000],\n",
      "         [  8.0000,  67.0000,   0.0000],\n",
      "         [  0.0000,  75.0000,   0.0000],\n",
      "         [  4.0000,  80.0000,   1.0000],\n",
      "         [  5.0000,  87.0000,   1.0000],\n",
      "         [  3.0000,  96.0000,   1.0000],\n",
      "         [  6.0000, 103.0000,   1.0000],\n",
      "         [  5.0000, 107.0000,   1.0000],\n",
      "         [  0.0000, 114.0000,   0.0000],\n",
      "         [  3.0000, 122.0000,   0.0000]],\n",
      "\n",
      "        [[  9.0000,   9.0000,   1.0000],\n",
      "         [  1.0000,  16.0000,   1.0000],\n",
      "         [  2.0000,  17.0000,   0.0000],\n",
      "         [  0.0000,  19.0000,   1.0000],\n",
      "         [  4.0000,  26.0000,   1.0000],\n",
      "         [  0.0000,  30.0000,   0.0000],\n",
      "         [  6.0000,  36.0000,   0.0000],\n",
      "         [  4.0000,  45.0000,   0.0000],\n",
      "         [  6.0000,  52.0000,   1.0000],\n",
      "         [  2.0000,  54.0000,   0.0000],\n",
      "         [  8.0000,  63.0000,   0.0000],\n",
      "         [  8.0000,  67.0000,   0.0000],\n",
      "         [  0.0000,  75.0000,   0.0000],\n",
      "         [  4.0000,  80.0000,   1.0000],\n",
      "         [  5.0000,  87.0000,   1.0000],\n",
      "         [  3.0000,  96.0000,   1.0000],\n",
      "         [  6.0000, 103.0000,   1.0000],\n",
      "         [  5.0000, 107.0000,   1.0000],\n",
      "         [  0.0000, 114.0000,   0.0000],\n",
      "         [  3.0000, 122.0000,   0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "#m = nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "KERNEL_LENGTH = 9\n",
    "KERNEL = Tensor(np.cumsum([.1]*KERNEL_LENGTH)[np.newaxis].transpose(1,0)).repeat(1, 1, 1, 1)\n",
    "INVERSE_KERNEL = torch.flip(KERNEL, dims=(2,))\n",
    "\n",
    "def conv_weight(gt_abs, pred_rel, gt_rel=None, indices=slice(0,None)):\n",
    "    \"\"\" BATCH, WIDTH (GT LENGTH), HEIGHT (VOCAB SIZE)\n",
    "        INDICES MUST BE SLICE/LIST\n",
    "    \"\"\"\n",
    "    width = gt_abs.shape[1]\n",
    "\n",
    "    cumsum = torch.zeros(*gt_abs.shape)\n",
    "    cumsum[:, KERNEL_LENGTH:, indices] = gt_abs[:, :width - KERNEL_LENGTH, indices]  # BATCH, WIDTH, VOCAB\n",
    "\n",
    "    if gt_rel is None:\n",
    "        gt_rel = relativefy_batch_torch(gt_abs.detach().clone(), indices=indices)\n",
    "\n",
    "    # Add channel dimension\n",
    "    gt_rel_exp = gt_rel.unsqueeze(1)[:,:,:,indices]  # BATCH, CHANNEL, WIDTH, VOCAB\n",
    "    pred_rel_exp = pred_rel.unsqueeze(1)[:,:,:,indices]\n",
    "\n",
    "    # Functionary way\n",
    "    gt_rel[:,:,indices] = functional.conv2d(gt_rel_exp, INVERSE_KERNEL, padding=[KERNEL_LENGTH - 1, 0]).squeeze(1)[:,:width]\n",
    "    pred_rel[:,:,indices] = functional.conv2d(pred_rel_exp, KERNEL, padding=[KERNEL_LENGTH - 1, 0]).squeeze(1)[:,:width] + gt_rel[:,:,indices] + cumsum[:,:,indices]\n",
    "    return pred_rel\n",
    "\n",
    "# Anything with itself should be equivalent to a cumulative sum\n",
    "x = conv_weight(gt,gt_rel.clone())\n",
    "np.testing.assert_almost_equal(x.numpy(), gt, decimal=5)\n",
    "\n",
    "# Should get back on track\n",
    "x = conv_weight(gt,pred.clone())\n",
    "np.testing.assert_almost_equal(x[:,-4:].numpy(), gt[:,-4:], decimal=5)\n",
    "np.testing.assert_almost_equal(x[:,0:6].numpy(), gt[:,0:6], decimal=5)\n",
    "\n",
    "# With batching\n",
    "gt2 = Tensor(np.r_[gt,gt])\n",
    "gt2_rel = Tensor(np.r_[gt_rel.clone(),gt_rel.clone()]) # pred is relative\n",
    "x = conv_weight(gt2,gt2_rel)\n",
    "np.testing.assert_almost_equal(x.numpy(), gt2, decimal=5)\n",
    "\n",
    "# With batching + index\n",
    "gt2 = Tensor(np.r_[gt,gt])\n",
    "gt2_rel = Tensor(np.r_[gt_rel.clone(),gt_rel.clone()]) # pred is relative\n",
    "x = conv_weight(gt2,gt2_rel, indices=[1,])\n",
    "np.testing.assert_almost_equal(x.numpy()[:,:,1], gt2[:,:,1], decimal=5)\n",
    "np.testing.assert_almost_equal(x.numpy()[:,:,0], gt2_rel[:,:,0], decimal=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumsum[:,:,:,kernel_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 20, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*gt.shape].insert(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwr",
   "language": "python",
   "name": "hwr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
