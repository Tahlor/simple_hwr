{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.41421356 1.41421356 1.41421356 1.41421356 1.41421356\n",
      " 1.41421356 1.41421356 1.41421356 1.41421356]\n",
      "[0.         1.41421356 1.41421356]\n",
      "[0.         1.41421356 1.41421356 1.41421356 1.41421356 0.\n",
      " 1.41421356 1.41421356 0.         1.41421356]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.41421356, 2.82842712, 4.24264069, 5.65685425,\n",
       "       5.65685425, 7.07106781, 8.48528137, 8.48528137, 9.89949494])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from pathlib import Path\n",
    "from data_processing.online_coordinate_data.create_dataset import *\n",
    "import matplotlib.pyplot as plt\n",
    "from hwr_utils import utils\n",
    "\n",
    "import numpy as np\n",
    "from hwr_utils.stroke_plotting import draw_from_gt\n",
    "\n",
    "def distance_metric(x,y):\n",
    "    \"\"\" Euclidean distance metric between x and x-1; first item in stroke has distance of epsilon\n",
    "    Args:\n",
    "        x: array-like\n",
    "        y: array-like\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    output = np.zeros(x.size)\n",
    "    output[1:] = ((x[:-1] - x[1:]) ** 2 + (y[:-1] - y[1:]) ** 2) ** (1 / 2)\n",
    "    #output[0] = 1e-8\n",
    "    return output\n",
    "\n",
    "def reparameterize_as_func_of_distance(x,y,start_strokes):\n",
    "    \"\"\" Instead of time, re-parameterize entire sequence as distance travelled\n",
    "\n",
    "    Args:\n",
    "        x: List of x's\n",
    "        y: List of y's\n",
    "        start_strokes: List of start stroke identifiers [1,0,0,1...\n",
    "\n",
    "    Returns:\n",
    "        distance travelled for each complete stroke\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x=np.array(x)\n",
    "    if isinstance(y, list):\n",
    "        y=np.array(y)\n",
    "\n",
    "    distances = distance_metric(x,y)\n",
    "    distances[start_strokes==1] = 0\n",
    "    cum_sum = np.cumsum(distances) # distance is 0 at first point; keeps length the same\n",
    "    return cum_sum\n",
    "\n",
    "\n",
    "x = np.array(range(0,10))\n",
    "y = x.copy()\n",
    "start_strokes = np.zeros(10)\n",
    "start_strokes[0] =1\n",
    "start_strokes[5] =1\n",
    "start_strokes[8] =1\n",
    "\n",
    "distances = distance_metric(x,y)\n",
    "print(distances)\n",
    "print(distances[start_strokes==1])\n",
    "distances[start_strokes==1] = 0\n",
    "print(distances)\n",
    "    \n",
    "reparameterize_as_func_of_distance(x,y,start_strokes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_strokes==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_substrokes(stroke_dict, desired_num_of_strokes=3):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        stroke_dict: ['x', 'y', 't', 'start_times', 'x_to_y', 'start_strokes', 'raw', 'tmin', 'tmax', 'trange']\n",
    "        desired_num_of_strokes:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if desired_num_of_strokes is None:\n",
    "        yield stroke_dict\n",
    "        return\n",
    "\n",
    "    start_args = np.where(stroke_dict.start_strokes==1)[0] # returns an \"array\" of the list, just take first index\n",
    "    start_args = np.append(start_args, None) # last start arg should be the end of the sequence\n",
    "\n",
    "    # If fewer strokes, just return the whole thing\n",
    "    if start_args.shape[0] <= desired_num_of_strokes:\n",
    "        return stroke_dict\n",
    "\n",
    "    for stroke_number in range(start_args.shape[0] - desired_num_of_strokes): # remember, last start_stroke is really the end stroke\n",
    "        start_idx = start_args[stroke_number]\n",
    "        end_idx = start_args[stroke_number + desired_num_of_strokes]\n",
    "\n",
    "        t = stroke_dict.t[start_idx:end_idx].copy()\n",
    "        x = stroke_dict.x[start_idx:end_idx].copy()\n",
    "        y = stroke_dict.y[start_idx:end_idx].copy()\n",
    "        raw = stroke_dict.raw[stroke_number:stroke_number + desired_num_of_strokes]\n",
    "        start_strokes = stroke_dict.start_strokes[start_idx:end_idx]\n",
    "        start_times = stroke_dict.start_times[stroke_number:stroke_number + desired_num_of_strokes + 1].copy()\n",
    "\n",
    "        y, scale_param = normalize(y)\n",
    "        x, scale_param = normalize(x, scale_param)\n",
    "        x_to_y = np.max(x) / np.max(y)\n",
    "\n",
    "        start_time = t[0]\n",
    "        t -= start_time\n",
    "        start_times -= start_time\n",
    "        output = edict({\"x\": x,\n",
    "                        \"y\": y,\n",
    "                        \"t\": t,\n",
    "                        \"start_times\": start_times,\n",
    "                        \"start_strokes\": start_strokes,\n",
    "                        \"x_to_y\":x_to_y,\n",
    "                        \"raw\":raw})\n",
    "        \n",
    "        assert start_times[0]==t[0]\n",
    "        yield output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \"../../data/online_coordinate_data/3_stroke_16_v2/train_online_coords.json\"\n",
    "# FROM ORIGINAL XMLs\n",
    "json_path=\"../../data/prepare_online_data/online_augmentation.json\"\n",
    "original_img_folder = \"prepare_online_data/lineImages\"\n",
    "xml_root = \"../../data/prepare_online_data/line-level-xml/lineStrokes\"\n",
    "\n",
    "# # FROM GENERATED XMLs\n",
    "# json_path=\"../../data/online_coordinate_data/3_stroke_16_v2/train_online_coords.json\"\n",
    "# original_img_folder = \"online_coordinate_data/3_stroke_16_v2/images\"\n",
    "# xml_root = \"../../data/prepare_online_data/line-level-xml/lineStrokes\"\n",
    "\n",
    "\n",
    "with open(json_path) as f:\n",
    "    output_dict = json.load(f)\n",
    "print(output_dict[0].keys())\n",
    "\n",
    "for i in output_dict:\n",
    "    if \"a01-001w-08\" in i[\"image_path\"]:\n",
    "        instance = i\n",
    "        print(i[\"image_path\"])\n",
    "\n",
    "rel_path = Path(instance[\"image_path\"]).relative_to(original_img_folder).with_suffix(\".xml\")\n",
    "xml_path = xml_root / rel_path\n",
    "print(xml_path)\n",
    "\n",
    "\n",
    "stroke_list, _ = read_stroke_xml(xml_path)\n",
    "print(stroke_list[1])\n",
    "stroke_dict = prep_stroke_dict(stroke_list, time_interval=0, scale_time_distance=True) # list of dictionaries, 1 per file\n",
    "\n",
    "\n",
    "xx = list(get_all_substrokes(stroke_dict))\n",
    "xx = [stroke_dict]\n",
    "for x in xx:\n",
    "    plt.scatter(x[\"x\"], x[\"y\"])\n",
    "    plt.plot(x[\"x\"], x[\"y\"])\n",
    "    plt.show()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../../data/online_coordinate_data/3_stroke_16_v2/train_online_coords.json\"\n",
    "\n",
    "with open(json_path) as f:\n",
    "    output_dict = json.load(f)\n",
    "\n",
    "for x in output_dict:\n",
    "    print(x.keys())\n",
    "    plt.scatter(x[\"gt\"][0], x[\"gt\"][1])\n",
    "    plt.plot(x[\"gt\"][0], x[\"gt\"][1])\n",
    "    plt.show()\n",
    "    stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../../data/online_coordinate_data/3_stroke_64_v2/train_online_coords.json\"\n",
    "\n",
    "with open(json_path) as f:\n",
    "    output_dict = json.load(f)\n",
    "\n",
    "for x in output_dict:\n",
    "    if \"a01-001w-08\" in x[\"image_path\"]:\n",
    "        print(x.keys())\n",
    "        plt.scatter(x[\"x\"], x[\"y\"])\n",
    "        plt.plot(x[\"x\"], x[\"y\"])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../../data/online_coordinate_data/8_stroke_vSmall_16/train_online_coords.json\"\n",
    "\n",
    "with open(json_path) as f:\n",
    "    output_dict = json.load(f)\n",
    "\n",
    "    \n",
    "for x in output_dict:\n",
    "    #print(x[\"full_img_path\"])\n",
    "    if \"a01-001w-08\" in x[\"full_img_path\"]:\n",
    "        x = prep_stroke_dict(x[\"raw\"], time_interval=0, scale_time_distance=True) # list of dictionaries, 1 per file\n",
    "        plt.scatter(x[\"x\"], x[\"y\"])\n",
    "        plt.plot(x[\"x\"], x[\"y\"])\n",
    "        plt.axis('off')\n",
    "        plt.axis('square')\n",
    "        plt.show()\n",
    "        print(x.keys())\n",
    "        \n",
    "# dict_keys(['full_img_path', 'xml_path', 'image_path', 'dataset', 'x', 'y', 't', 'start_times', 'start_strokes', 'x_to_y', 'raw', 'shape']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['full_img_path', 'xml_path', 'image_path', 'dataset', 'x', 'y', 't', 'start_times', 'start_strokes', 'x_to_y', 'raw', 'shape'])\n",
      "dict_keys(['x', 'y', 't', 'd', 'start_times', 'start_distances', 'x_to_y', 'start_strokes', 'raw', 'tmin', 'tmax', 'trange', 'drange'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ..., 255, 255, 255],\n",
       "       [255,   0,   0, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = \"../../data/online_coordinate_data/8_stroke_vSmall_16/train_online_coords.json\"\n",
    "\n",
    "parameter = \"t\"\n",
    "with open(json_path) as f:\n",
    "    output_dict = json.load(f)\n",
    "  \n",
    "i = 0\n",
    "for x in output_dict:\n",
    "    #print(x[\"full_img_path\"])\n",
    "    if \"a01-001w-08\" in x[\"full_img_path\"]:\n",
    "        i += 1\n",
    "        if i ==20:\n",
    "            break\n",
    "\n",
    "# Original Processing\n",
    "print(x.keys())\n",
    "gt = np.array([x[\"x\"],x[\"y\"],x[\"start_strokes\"]]).transpose(1,0)\n",
    "draw_from_gt(gt, show=True, use_stroke_number=False)\n",
    "\n",
    "output = prep_stroke_dict(x[\"raw\"], time_interval=0, scale_time_distance=True) # list of dictionaries, 1 per file\n",
    "print(output.keys())\n",
    "\n",
    "# After prepping\n",
    "gt = np.array([output[\"x\"],output[\"y\"],output[\"start_strokes\"]]).transpose(1,0)\n",
    "draw_from_gt(gt, show=True, use_stroke_number=False)\n",
    "\n",
    "# After sampling\n",
    "x_func, y_func = stroke_recovery.create_functions_from_strokes(output, parameter=parameter) # can be d if the function should be a function of distance\n",
    "starts = output.start_times if parameter==\"t\" else output.start_distances\n",
    "x, y, is_start_stroke = stroke_recovery.sample(x_func, y_func, starts, 1000, noise=None)\n",
    "\n",
    "# plt.scatter(x,y)\n",
    "# plt.plot(x,y)\n",
    "gt = np.array([x,y,is_start_stroke]).transpose([1,0])\n",
    "draw_from_gt(gt, show=True, use_stroke_number=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hwr_utils.stroke_recovery import *\n",
    "\n",
    "background = tuple([255])\n",
    "\n",
    "img = Image.new(\"L\", (50, 50), background)\n",
    "draw = ImageDraw.Draw(img)\n",
    "color = 0\n",
    "linewidth = 2\n",
    "pil_format = [np.array([[10,20,30],[10,20,30]]), np.array([[15],[15]])]\n",
    "\n",
    "for line in pil_format:\n",
    "    if line.size > 2:\n",
    "        line = [tuple(x) for x in line.flatten().reshape(-1,2).tolist()]\n",
    "        draw.line(line, fill=color, width=linewidth, joint='curve')\n",
    "        draw.ellipse((15, 15, 16, 16), fill = 'blue', outline ='blue')\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hwr_utils.stroke_recovery import *\n",
    "\n",
    "background = tuple([255])\n",
    "\n",
    "img = Image.new(\"L\", (50, 50), background)\n",
    "draw = ImageDraw.Draw(img)\n",
    "color = 0\n",
    "linewidth = 3\n",
    "pil_format = [np.array([[10,20,30],[10,20,30]]), np.array([[15],[15]])]\n",
    "\n",
    "for line in pil_format:\n",
    "    if line.size > 2:\n",
    "        line = [tuple(x) for x in line.flatten().reshape(-1,2).tolist()]\n",
    "        draw.line(line, fill=color, width=linewidth, joint='curve')\n",
    "    elif line.size == 2:\n",
    "        line1 = line - linewidth/2\n",
    "        line2 = line + linewidth/2\n",
    "        line = np.r_[line1, line2].flatten().tolist()\n",
    "        draw.ellipse(line, fill = 'black', outline ='black')\n",
    "\n",
    "# line = (20,5,6,19)\n",
    "# draw.ellipse(line, fill = 'blue', outline ='blue')\n",
    "# draw.ellipse((15, 15, 16, 16), fill = 'blue', outline ='blue')\n",
    "\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"../../data/online_coordinate_data/8_stroke_vSmall_16/train_online_coords.json\"\n",
    "\n",
    "parameter = \"d\"\n",
    "with open(json_path) as f:\n",
    "    output_dict = json.load(f)\n",
    "  \n",
    "i = 0\n",
    "for x in output_dict:\n",
    "    #print(x[\"full_img_path\"])\n",
    "    if \"a01-001w-08\" in x[\"full_img_path\"]:\n",
    "        i += 1\n",
    "        if i ==20:\n",
    "            break\n",
    "         \n",
    "output = prep_stroke_dict(x[\"raw\"], time_interval=0, scale_time_distance=True) # list of dictionaries, 1 per file\n",
    "\n",
    "# After sampling\n",
    "x_func, y_func = stroke_recovery.create_functions_from_strokes(output, parameter=parameter) # can be d if the function should be a function of distance\n",
    "starts = output.start_times if parameter==\"t\" else output.start_distances\n",
    "x, y, is_start_stroke = stroke_recovery.sample(x_func, y_func, starts, 1000, noise=None)\n",
    "gt = np.array([x,y,is_start_stroke]).transpose([1,0])\n",
    "img = draw_from_gt(gt, show=True, use_stroke_number=False, plot_points=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-9b487efb9e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbad_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mdraw_from_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_stroke_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#draw_from_gt(pred, show=True, use_stroke_number=False, plot_points=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "from hwr_utils.stroke_recovery import *\n",
    "max_dist = .2\n",
    "path = \"/media/data/GitHub/simple_hwr/RESULTS/TEST_20200220_163954-baseline/imgs/1/train/example_data.pickle\"\n",
    "path = r\"/home/taylor/shares/brodie/github/simple_hwr/RESULTS/ver2/20200220_164052-normal/imgs/9/train/example_data.pickle\"\n",
    "d = utils.unpickle_it(path)\n",
    "\n",
    "preds = [x.detach().numpy() for x in d[\"preds\"]]\n",
    "item = d[\"item\"]\n",
    "gt = d[\"item\"][\"gt_list\"][0].numpy()\n",
    "pred = preds[0].transpose(1,0)\n",
    "gt[:,2] = relativefy_numpy(gt[:,2])\n",
    "\n",
    "gt[175][0:2] = np.array([2.5,.9])\n",
    "gt[175][0:3] = np.array([2.5,.9,0])\n",
    "\n",
    "\n",
    "distances = distance_metric(gt[:, 0], gt[:, 1])\n",
    "\n",
    "# Where are the distances big\n",
    "idx = np.argwhere(distances > max_dist).reshape(-1)\n",
    "not_first_stroke = np.argwhere(gt[:, 2]==0).flatten()\n",
    "bad_points = idx[np.where(np.diff(idx) == 1)]\n",
    "bad_points = np.intersect1d(not_first_stroke, bad_points)\n",
    "\n",
    "# Delete them\n",
    "gt = np.delete(gt, bad_points, axis=0)\n",
    "\n",
    "# Add new start point\n",
    "gt[bad_points, 2] = 1\n",
    "print(bad_points)\n",
    "stop\n",
    "draw_from_gt(gt, show=True, use_stroke_number=True, plot_points=True)\n",
    "#draw_from_gt(pred, show=True, use_stroke_number=False, plot_points=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 26,  4, 22, 27, 21,  1,  4, 11, 63, 32, 19, 45, 27, 40, 16, 12,\n",
       "       22,  3, 67, 28])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/data/GitHub/simple_hwr/RESULTS/TEST_20200220_163954-baseline/imgs/1/train/example_data.pickle\"\n",
    "path = r\"/home/taylor/shares/brodie/github/simple_hwr/RESULTS/ver2/20200220_164052-normal/imgs/21/train/example_data.pickle\"\n",
    "d = utils.unpickle_it(path)\n",
    "\n",
    "preds = [x.detach().numpy() for x in d[\"preds\"]]\n",
    "item = d[\"item\"]\n",
    "gt = d[\"item\"][\"gt_list\"][0].numpy()\n",
    "pred = preds[0].transpose(1,0)\n",
    "\n",
    "draw_from_gt(gt, show=True, use_stroke_number=True, plot_points=True)\n",
    "draw_from_gt(pred, show=True, use_stroke_number=False, plot_points=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwr5",
   "language": "python",
   "name": "hwr5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
