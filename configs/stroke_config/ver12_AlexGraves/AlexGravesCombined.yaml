## TO DO IMMEDIATELY:
# DEBUG TEST/TRAIN LOSS
# RELATIVE COORDS CONFIG

# Load model
load_path: /fslhome/tarch/fsl_groups/fslg_hwr/compute/taylor_simple_hwr/RESULTS/20200301-PRETRAIN/normal_preload_model.pt
load_path: /media/data/GitHub/simple_hwr/RESULTS/pretrained/dtw_train_2.9/normal_preload_model.pt
load_path: /fslhome/tarch/fsl_groups/fslg_hwr/compute/taylor_simple_hwr/RESULTS/20200301-PRETRAIN/normal_preload_model.pt
load_path: "/home/taylor/github/simple_hwr/RESULTS/ver5/March 10/normal_v4_model.part"
load_path: /home/taylor/github/simple_hwr/RESULTS/pretrained/normal_SOS_EOS_ORDERED_brodie_model.pt
TESTING: false # this is for debugging, do it on a small dataset
load_path: ./RESULTS/pretrained/adapted_v2/dtw_adaptive_new2_restartLR_model.pt # GT3
load_path: ./RESULTS/pretrained/with_EOS/normal_preload_model.pt # GT4
load_path: /media/data/GitHub/simple_hwr/results/stroke_config/ver12_AlexGraves/20200513_223906-AlexGraves_MAIN/AlexGraves_model.pt
load_path: /media/data/GitHub/simple_hwr/results/stroke_config/ver12_AlexGraves/20200519_173155-AlexGraves2/AlexGraves2_model.pt
load_path: /media/data/GitHub/simple_hwr/RESULTS/ver12_AlexGraves/20200530_011807-AlexGravesCombined/AlexGravesCombined_model.pt
load_path: ./results/AlexGravesCombined_super_images_only/20200601_165606-AlexGravesCombined_super_images_only/AlexGravesCombined_super_images_only_model.pt
load_path: false

load_optimizer: false # load LR and per-parameter LR's from saved state
reset_LR: true # reset the global LR if loading optimizer - this resets it based on epoch

results_dir_override: # will override the subexperiment folder logic
test_only: false # Do not train
offline_pred: false
logging: info
gpu_if_available: true
model_name: AlexGravesCombined

# General
output_folder: ./results
epochs_to_run: 1000
update_freq: 100 # print out updates, update graphs etc. after this many updates
save_freq: 1     # save the model every X epochs
use_visdom: true
debug: off
truncate: false

model_definition:
  mode: random

dataset:
  img_height: 61
  include_synthetic: false
  num_of_channels: 1
  image_prep: pil_with_distortion
  #adapted_gt_path: ./RESULTS/pretrained/training_dataset.npy
  resample: false





# Training data
#dataset_folder: online_coordinate_data/8_stroke_vSmall_16
#dataset_folder: online_coordinate_data/8_stroke_vFull
data_root_fsl: ../hw_data/strokes
data_root_local: data
dataset_folder: online_coordinate_data/MAX_stroke_vFull
dataset_folder: online_coordinate_data/MAX_stroke_vTEST_AUGMENTFull
dataset_folder: online_coordinate_data/MAX_stroke_vlargeTrnSetFull

# WARP
warp: true

# LR schedule
learning_rate: 1e-4          # LR
scheduler_step: null         # Every X steps, multiply LR by gamma
scheduler_gamma: .95         # LR decay rate

test_size: null
train_size: null
batch_size: 20

# interpolated_sos: interpolated # normal: use 1's for starts; interpolated: start is a "0" and increases from there based on distance of stroke
gt_format: # if relative etc., specify that here; e.g., opts:rel
  - x
  - y
  - sos
  - eos # not used

loss_fns:
  - name: synthloss

first_loss_epochs: 1
training_nn_loss: false # calculate nearest neighbor loss on every training instance; <- this is basically just DTW loss, without the time constraint? really only useful for offline images with pixels etc.

## CNN
cnn_type: default # default64; CNN output width similar to input width; default: CNN output is like 1/4 the input width

# CoordConv
  # x-scaled from -1 to 1
  # x-scaled to be same scale as y
coordconv: true
coordconv_method: y_abs
coordconv_0_center: false

# Visdom
visdom_port: 9001
